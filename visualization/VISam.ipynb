{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b3a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading neural responses and area labels ...\n",
      "Filtering to VISam: 2040 / 39209 neurons\n",
      "Data shape after filtering: 2040Ã—118Ã—50Ã—1\n",
      "Averaged responses: (2040, 118)\n",
      "ðŸ”¹ Loading ViT class labels ...\n",
      "Found 118 scene labels.\n",
      "ðŸ”¹ Running PCA on VISam neurons ...\n",
      "Selecting 61 PCs to cover 90% variance (90.03%)\n",
      "Saving PC1/61 ...\n",
      "Saving PC2/61 ...\n",
      "Saving PC3/61 ...\n",
      "Saving PC4/61 ...\n",
      "Saving PC5/61 ...\n",
      "Saving PC6/61 ...\n",
      "Saving PC7/61 ...\n",
      "Saving PC8/61 ...\n",
      "Saving PC9/61 ...\n",
      "Saving PC10/61 ...\n",
      "Saving PC11/61 ...\n",
      "Saving PC12/61 ...\n",
      "Saving PC13/61 ...\n",
      "Saving PC14/61 ...\n",
      "Saving PC15/61 ...\n",
      "Saving PC16/61 ...\n",
      "Saving PC17/61 ...\n",
      "Saving PC18/61 ...\n",
      "Saving PC19/61 ...\n",
      "Saving PC20/61 ...\n",
      "Saving PC21/61 ...\n",
      "Saving PC22/61 ...\n",
      "Saving PC23/61 ...\n",
      "Saving PC24/61 ...\n",
      "Saving PC25/61 ...\n",
      "Saving PC26/61 ...\n",
      "Saving PC27/61 ...\n",
      "Saving PC28/61 ...\n",
      "Saving PC29/61 ...\n",
      "Saving PC30/61 ...\n",
      "Saving PC31/61 ...\n",
      "Saving PC32/61 ...\n",
      "Saving PC33/61 ...\n",
      "Saving PC34/61 ...\n",
      "Saving PC35/61 ...\n",
      "Saving PC36/61 ...\n",
      "Saving PC37/61 ...\n",
      "Saving PC38/61 ...\n",
      "Saving PC39/61 ...\n",
      "Saving PC40/61 ...\n",
      "Saving PC41/61 ...\n",
      "Saving PC42/61 ...\n",
      "Saving PC43/61 ...\n",
      "Saving PC44/61 ...\n",
      "Saving PC45/61 ...\n",
      "Saving PC46/61 ...\n",
      "Saving PC47/61 ...\n",
      "Saving PC48/61 ...\n",
      "Saving PC49/61 ...\n",
      "Saving PC50/61 ...\n",
      "Saving PC51/61 ...\n",
      "Saving PC52/61 ...\n",
      "Saving PC53/61 ...\n",
      "Saving PC54/61 ...\n",
      "Saving PC55/61 ...\n",
      "Saving PC56/61 ...\n",
      "Saving PC57/61 ...\n",
      "Saving PC58/61 ...\n",
      "Saving PC59/61 ...\n",
      "Saving PC60/61 ...\n",
      "Saving PC61/61 ...\n",
      "\n",
      "âœ… All 61 VISam components saved in 'mouse_pca_panels_VISam/'\n",
      "ðŸ”¹ Building index.html ...\n",
      "âœ… HTML index created: mouse_pca_panels_VISam/index.html\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Full PCA interpretability atlas for Mouse Neural Responses (filtered to VISam neurons).\n",
    "\n",
    "For each PC:\n",
    " - Plotly bar chart (top Â±10 scenes)\n",
    " - Matplotlib mosaic of top 10 and bottom 10 image thumbnails\n",
    " - Builds combined index.html for browsing all PCs\n",
    "\"\"\"\n",
    "\n",
    "import os, pickle, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "NEURAL_PATH = '/home/maria/LuckyMouse/pixel_transformer_neuro/data/processed/hybrid_neural_responses.npy'\n",
    "AREA_PATH   = 'area_labels.npy'\n",
    "VIT_PATH    = '/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "IMGS_PATH   = '/home/maria/MITNeuralComputation/vit_embeddings/images'\n",
    "OUT_DIR     = 'mouse_pca_panels_VISam'\n",
    "TOP_K       = 10\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD NEURAL DATA + FILTER BY AREA\n",
    "# ---------------------------------------------------------------\n",
    "print(\"ðŸ”¹ Loading neural responses and area labels ...\")\n",
    "dat = np.load(NEURAL_PATH)   # shape: (neurons, n_images * n_trials * n_time)\n",
    "area_labels = np.load(AREA_PATH)\n",
    "\n",
    "if len(area_labels) != dat.shape[0]:\n",
    "    raise ValueError(f\"Mismatch: {len(area_labels)} labels vs {dat.shape[0]} neurons\")\n",
    "\n",
    "mask = (area_labels == \"VISam\")\n",
    "print(f\"Filtering to VISam: {mask.sum()} / {len(area_labels)} neurons\")\n",
    "dat = dat[mask]\n",
    "\n",
    "# infer stimulus structure\n",
    "n_images, n_trials = 118, 50\n",
    "n_neurons, n_total = dat.shape\n",
    "n_time = n_total // (n_images * n_trials)\n",
    "print(f\"Data shape after filtering: {n_neurons}Ã—{n_images}Ã—{n_trials}Ã—{n_time}\")\n",
    "\n",
    "# reshape â†’ average across trials and time\n",
    "dat = dat.reshape(n_neurons, n_images, n_trials, n_time)\n",
    "X_mean = dat.mean(axis=(2, 3))  # shape (neurons Ã— images)\n",
    "print(\"Averaged responses:\", X_mean.shape)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD ViT LABELS (scene names)\n",
    "# ---------------------------------------------------------------\n",
    "print(\"ðŸ”¹ Loading ViT class labels ...\")\n",
    "try:\n",
    "    from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "    class_names = ViT_B_16_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "except Exception:\n",
    "    class_names = [f\"class_{i}\" for i in range(1000)]\n",
    "\n",
    "with open(VIT_PATH, 'rb') as f:\n",
    "    vit_logits = pickle.load(f)['natural_scenes']\n",
    "\n",
    "top1_idx = np.argmax(vit_logits, axis=1)\n",
    "scene_labels = [class_names[i] for i in top1_idx]\n",
    "image_ids = [f\"scene_{i:03d}\" for i in range(n_images)]\n",
    "print(f\"Found {len(scene_labels)} scene labels.\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# PCA\n",
    "# ---------------------------------------------------------------\n",
    "print(\"ðŸ”¹ Running PCA on VISam neurons ...\")\n",
    "X_centered = X_mean - X_mean.mean(axis=0, keepdims=True)\n",
    "pca_full = PCA(n_components=min(X_centered.shape), random_state=0)\n",
    "pca_full.fit(X_centered)\n",
    "cumulative_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "n_components = np.searchsorted(cumulative_var, 0.90) + 1\n",
    "print(f\"Selecting {n_components} PCs to cover 90% variance \"\n",
    "      f\"({100*cumulative_var[n_components-1]:.2f}%)\")\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=0)\n",
    "U = pca.fit_transform(X_centered)  # neuron projections\n",
    "V = pca.components_.T              # image loadings\n",
    "expl_var = pca.explained_variance_ratio_\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Plotly: bar chart (scenes)\n",
    "# ---------------------------------------------------------------\n",
    "def plot_pc_semantics_plotly(V, class_names, pc_idx, top_k=10):\n",
    "    v_raw = V[:, pc_idx]\n",
    "    v = v_raw - np.mean(v_raw)  # recenter for visualization only\n",
    "\n",
    "    pos_idx = np.argsort(v)[-top_k:][::-1]\n",
    "    neg_idx = np.argsort(v)[:top_k]\n",
    "\n",
    "    pos_names = [class_names[i] for i in pos_idx]\n",
    "    neg_names = [class_names[i] for i in neg_idx]\n",
    "    pos_y = [name + \" \" for name in pos_names]  # prevent label overlap\n",
    "    neg_y = [name for name in neg_names]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=v[pos_idx], y=pos_y,\n",
    "        orientation='h', marker_color='green', name='Positive'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=v[neg_idx], y=neg_y,\n",
    "        orientation='h', marker_color='red', name='Negative'\n",
    "    ))\n",
    "\n",
    "    xmax = float(np.max(np.abs(v))) if v.size else 1.0\n",
    "    fig.update_xaxes(range=[-xmax, xmax])\n",
    "    fig.update_layout(\n",
    "        title=f\"PC{pc_idx+1} â€” top Â±{top_k} scenes (VISam)\",\n",
    "        barmode='overlay',\n",
    "        xaxis_title=\"Loading weight (centered for viz)\",\n",
    "        yaxis_title=\"Scene\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Matplotlib: 10Ã—2 image mosaic (top/bottom)\n",
    "# ---------------------------------------------------------------\n",
    "def save_top_images(V, pc_idx, image_ids, imgs_path, out_dir, top_n=10):\n",
    "    scores = V[:, pc_idx]\n",
    "    top_idx = np.argsort(scores)[-top_n:][::-1]\n",
    "    bot_idx = np.argsort(scores)[:top_n]\n",
    "\n",
    "    fig, axes = plt.subplots(2, top_n, figsize=(2.5 * top_n, 5))\n",
    "    for i, idx in enumerate(top_idx):\n",
    "        img_name = f\"{image_ids[idx]}.png\"\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        if os.path.exists(img_path):\n",
    "            axes[0, i].imshow(Image.open(img_path), cmap='gray')\n",
    "        axes[0, i].set_title(f\"Top {i+1} ({scores[idx]:.2f})\", fontsize=8)\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "    for i, idx in enumerate(bot_idx):\n",
    "        img_name = f\"{image_ids[idx]}.png\"\n",
    "        img_path = os.path.join(imgs_path, img_name)\n",
    "        if os.path.exists(img_path):\n",
    "            axes[1, i].imshow(Image.open(img_path), cmap='gray')\n",
    "        axes[1, i].set_title(f\"Bottom {i+1} ({scores[idx]:.2f})\", fontsize=8)\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Example images for PC{pc_idx+1} (VISam, {expl_var[pc_idx]*100:.2f}% variance)\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(out_dir, f\"PC{pc_idx+1:02d}_images.png\")\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# MAIN LOOP\n",
    "# ---------------------------------------------------------------\n",
    "for pc_idx in range(n_components):\n",
    "    print(f\"Saving PC{pc_idx+1}/{n_components} ...\")\n",
    "\n",
    "    # Plotly bar chart\n",
    "    fig = plot_pc_semantics_plotly(V, scene_labels, pc_idx, top_k=TOP_K)\n",
    "    fig.write_html(os.path.join(OUT_DIR, f\"PC{pc_idx+1:02d}_bars.html\"))\n",
    "\n",
    "    # Image mosaic\n",
    "    save_top_images(V, pc_idx, image_ids, IMGS_PATH, OUT_DIR, top_n=TOP_K)\n",
    "\n",
    "print(f\"\\nâœ… All {n_components} VISam components saved in '{OUT_DIR}/'\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# HTML INDEX BUILDER\n",
    "# ---------------------------------------------------------------\n",
    "print(\"ðŸ”¹ Building index.html ...\")\n",
    "index_path = os.path.join(OUT_DIR, \"index.html\")\n",
    "\n",
    "bar_files = sorted([f for f in os.listdir(OUT_DIR) if f.endswith(\"_bars.html\")])\n",
    "pcs = [f.split(\"_\")[0] for f in bar_files]\n",
    "\n",
    "html_parts = [\n",
    "    \"<html><head>\",\n",
    "    \"<meta charset='utf-8'/>\",\n",
    "    \"<title>VISam PCA Atlas</title>\",\n",
    "    \"<style>\",\n",
    "    \"body { font-family: sans-serif; background-color: #f9f9f9; margin: 40px; }\",\n",
    "    \"h2 { margin-top: 60px; }\",\n",
    "    \"iframe { border: none; width: 100%; height: 500px; }\",\n",
    "    \"img { width: 100%; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.2); }\",\n",
    "    \".panel { background: white; padding: 20px; border-radius: 10px; margin-bottom: 40px; \"\n",
    "    \"box-shadow: 0 0 10px rgba(0,0,0,0.05); }\",\n",
    "    \"a { text-decoration: none; color: #3366cc; }\",\n",
    "    \"</style></head><body>\",\n",
    "    \"<h1>Mouse Brain PCA Interpretability Atlas â€” VISam</h1>\",\n",
    "    f\"<p>Found {len(pcs)} components in <code>{OUT_DIR}</code>.</p>\",\n",
    "    \"<h3>Jump to component:</h3><ul>\",\n",
    "]\n",
    "\n",
    "# Table of contents\n",
    "for pc_prefix in pcs:\n",
    "    num = pc_prefix.replace(\"PC\", \"\")\n",
    "    html_parts.append(f\"<li><a href='#{pc_prefix}'>PC{int(num)}</a></li>\")\n",
    "html_parts.append(\"</ul>\")\n",
    "\n",
    "# Panels\n",
    "for pc_prefix in pcs:\n",
    "    num = pc_prefix.replace(\"PC\", \"\")\n",
    "    bar_html = f\"{pc_prefix}_bars.html\"\n",
    "    img_png = f\"{pc_prefix}_images.png\"\n",
    "\n",
    "    html_parts.append(f\"<div class='panel' id='{pc_prefix}'>\")\n",
    "    html_parts.append(f\"<h2>Principal Component {int(num)}</h2>\")\n",
    "    if os.path.exists(os.path.join(OUT_DIR, bar_html)):\n",
    "        html_parts.append(f\"<iframe src='{bar_html}'></iframe>\")\n",
    "    if os.path.exists(os.path.join(OUT_DIR, img_png)):\n",
    "        html_parts.append(f\"<img src='{img_png}' alt='PC{num} images'/>\")\n",
    "    html_parts.append(\"</div>\")\n",
    "\n",
    "html_parts.append(\"</body></html>\")\n",
    "\n",
    "with open(index_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(html_parts))\n",
    "\n",
    "print(f\"âœ… HTML index created: {index_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
