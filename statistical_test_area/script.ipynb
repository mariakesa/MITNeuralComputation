{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c3f82df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loading ViT embeddings...\n",
      "ViT PCs covering 90% variance: 44\n",
      "üîπ Loading neural responses (VISpm)...\n",
      "VISpm PCs covering 90% variance: 69\n",
      "üîπ Computing all pairwise correlations...\n",
      "Total tests performed: 3036\n",
      "‚úÖ 2 / 3036 correlations survived FDR correction (q < 0.05).\n",
      "\n",
      "Significant pairs (ViT PC ‚Üî Brain PC):\n",
      "  ViT PC 1 ‚Üî VISpm PC 4 | r = +0.436, p = 7.87e-07, q = 2.39e-03\n",
      "  ViT PC34 ‚Üî VISpm PC58 | r = -0.410, p = 4.01e-06, q = 6.09e-03\n",
      "\n",
      "üíæ Results saved to vitpm PC pairs (q < 0.05)_VISpm_corr_results.npz\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Correlation test between ViT and Mouse Brain PCA components.\n",
    "\n",
    " - Tests H0: corr(ViT PC_i, Brain PC_j) = 0\n",
    " - Uses all PCs explaining ‚â•90% variance in each space\n",
    " - Applies Benjamini‚ÄìHochberg correction for multiple testing\n",
    " - Prints significant pairs and summary statistics\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.special import softmax\n",
    "from skbio.stats.composition import clr\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "VIT_PATH = '/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "NEURAL_PATH = '/home/maria/LuckyMouse/pixel_transformer_neuro/data/processed/hybrid_neural_responses.npy'\n",
    "AREAS_PATH = '/home/maria/MITNeuralComputation/visualization/brain_area.npy'       # brain area label per neuron\n",
    "AREA_NAME = 'VISpm'                 # choose brain area\n",
    "N_IMAGES, N_TRIALS = 118, 50\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD ViT EMBEDDINGS AND RUN PCA\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Loading ViT embeddings...\")\n",
    "with open(VIT_PATH, 'rb') as f:\n",
    "    vit_logits = pickle.load(f)['natural_scenes']\n",
    "embeddings = np.asarray(vit_logits)\n",
    "X = softmax(embeddings, axis=1)\n",
    "X_clr = clr(X + 1e-12)\n",
    "\n",
    "pca_vit_full = PCA(n_components=min(X_clr.shape), random_state=0)\n",
    "pca_vit_full.fit(X_clr)\n",
    "vit_cumvar = np.cumsum(pca_vit_full.explained_variance_ratio_)\n",
    "vit_ncomp = np.searchsorted(vit_cumvar, 0.90) + 1\n",
    "print(f\"ViT PCs covering 90% variance: {vit_ncomp}\")\n",
    "\n",
    "vit_pca = PCA(n_components=vit_ncomp, random_state=0)\n",
    "vit_U = vit_pca.fit_transform(X_clr)      # (images √ó vit_ncomp)\n",
    "vit_var = vit_pca.explained_variance_ratio_\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD AND FILTER BRAIN DATA\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"üîπ Loading neural responses ({AREA_NAME})...\")\n",
    "dat = np.load(NEURAL_PATH, mmap_mode='r')\n",
    "areas = np.load(AREAS_PATH, allow_pickle=True)\n",
    "mask = areas == AREA_NAME\n",
    "dat = dat[mask]\n",
    "n_neurons, n_total = dat.shape\n",
    "n_time = n_total // (N_IMAGES * N_TRIALS)\n",
    "dat = dat.reshape(n_neurons, N_IMAGES, N_TRIALS, n_time)\n",
    "X_mean = dat.mean(axis=(2, 3))  # (neurons √ó images)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# PCA ON BRAIN DATA\n",
    "# ---------------------------------------------------------------\n",
    "pca_brain_full = PCA(n_components=min(X_mean.shape), random_state=0)\n",
    "pca_brain_full.fit(X_mean - X_mean.mean(axis=0))\n",
    "brain_cumvar = np.cumsum(pca_brain_full.explained_variance_ratio_)\n",
    "brain_ncomp = np.searchsorted(brain_cumvar, 0.90) + 1\n",
    "print(f\"{AREA_NAME} PCs covering 90% variance: {brain_ncomp}\")\n",
    "\n",
    "pca_brain = PCA(n_components=brain_ncomp, random_state=0)\n",
    "brain_V = pca_brain.fit_transform(X_mean - X_mean.mean(axis=0))  # (neurons √ó brain_ncomp)\n",
    "brain_loadings = pca_brain.components_.T                         # (images √ó brain_ncomp)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CORRELATION TESTS\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Computing all pairwise correlations...\")\n",
    "r_vals, p_vals, pairs = [], [], []\n",
    "\n",
    "for i in range(vit_ncomp):\n",
    "    for j in range(brain_ncomp):\n",
    "        r, p = pearsonr(vit_U[:, i], brain_loadings[:, j])\n",
    "        r_vals.append(r)\n",
    "        p_vals.append(p)\n",
    "        pairs.append((i+1, j+1))  # 1-indexed for reporting\n",
    "\n",
    "r_vals = np.array(r_vals)\n",
    "p_vals = np.array(p_vals)\n",
    "\n",
    "n_tests = len(p_vals)\n",
    "print(f\"Total tests performed: {n_tests}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# MULTIPLE TESTING CORRECTION\n",
    "# ---------------------------------------------------------------\n",
    "reject, pvals_corrected, _, _ = multipletests(p_vals, alpha=ALPHA_FDR, method='fdr_bh')\n",
    "\n",
    "sig_idx = np.where(reject)[0]\n",
    "if len(sig_idx) == 0:\n",
    "    print(\"‚ùå No correlations survived FDR correction.\")\n",
    "else:\n",
    "    print(f\"‚úÖ {len(sig_idx)} / {n_tests} correlations survived FDR correction (q < {ALPHA_FDR}).\")\n",
    "    print(\"\\nSignificant pairs (ViT PC ‚Üî Brain PC):\")\n",
    "    for idx in sig_idx:\n",
    "        i, j = pairs[idx]\n",
    "        print(f\"  ViT PC{i:2d} ‚Üî {AREA_NAME} PC{j:2d} | r = {r_vals[idx]:+.3f}, p = {p_vals[idx]:.2e}, q = {pvals_corrected[idx]:.2e}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# SAVE RESULTS\n",
    "# ---------------------------------------------------------------\n",
    "out = {\n",
    "    \"pairs\": pairs,\n",
    "    \"r\": r_vals,\n",
    "    \"p_raw\": p_vals,\n",
    "    \"p_fdr\": pvals_corrected,\n",
    "    \"significant\": reject,\n",
    "    \"vit_ncomp\": vit_ncomp,\n",
    "    \"brain_ncomp\": brain_ncomp,\n",
    "}\n",
    "np.savez(f\"vit_{AREA_NAME}_corr_results.npz\", **out)\n",
    "print(f\"\\nüíæ Results saved to vitpm PC pairs (q < 0.05)_{AREA_NAME}_corr_results.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Running 5-fold cross-validation on significant PC pairs...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components=69 must be between 0 and min(n_samples, n_features)=59 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m brain_test_centered  = (brain_test  - train_mean_per_neuron).T  \u001b[38;5;66;03m# (images_test √ó neurons)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Fit PCA on training images √ó neurons matrix\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mbrain_pca\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrain_train_centered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Transform test data to get brain PC scores (images_test √ó ncomp)\u001b[39;00m\n\u001b[32m     34\u001b[39m brain_scores_test = brain_pca.transform(brain_test_centered)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/global_venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/global_venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:440\u001b[39m, in \u001b[36mPCA.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    424\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[32m    425\u001b[39m \n\u001b[32m    426\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    438\u001b[39m \u001b[33;03m        Returns the instance itself.\u001b[39;00m\n\u001b[32m    439\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/global_venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:540\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mfull\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcovariance_eigh\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandomized\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_truncated(X, n_components, xp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/global_venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:554\u001b[39m, in \u001b[36mPCA._fit_full\u001b[39m\u001b[34m(self, X, n_components, xp, is_array_api_compliant)\u001b[39m\n\u001b[32m    550\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    551\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn_components=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmle\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is only supported if n_samples >= n_features\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    552\u001b[39m         )\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= n_components <= \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    555\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn_components=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be between 0 and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(n_samples,\u001b[38;5;250m \u001b[39mn_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msvd_solver=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._fit_svd_solver\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m     )\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.mean_ = xp.mean(X, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# When X is a scipy sparse matrix, self.mean_ is a numpy matrix, so we need\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# to transform it to a 1D array. Note that this is not the case when X\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# is a scipy sparse array.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# TODO: remove the following two lines when scikit-learn only depends\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# on scipy versions that no longer support scipy.sparse matrices.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: n_components=69 must be between 0 and min(n_samples, n_features)=59 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 5-FOLD CROSS-VALIDATION ON SIGNIFICANT PC PAIRS (FIXED FINAL)\n",
    "# ---------------------------------------------------------------\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "if np.any(reject):\n",
    "    print(\"\\nüîπ Running 5-fold cross-validation on significant PC pairs...\")\n",
    "\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    cv_results = {tuple(pairs[idx]): [] for idx in sig_idx}\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(N_IMAGES)), 1):\n",
    "        # ---- Split data by image ----\n",
    "        vit_train, vit_test = X_clr[train_idx], X_clr[test_idx]\n",
    "        brain_train, brain_test = X_mean[:, train_idx], X_mean[:, test_idx]\n",
    "\n",
    "        # ---- ViT PCA ----\n",
    "        vit_pca = PCA(n_components=vit_ncomp, random_state=0)\n",
    "        vit_U_train = vit_pca.fit_transform(vit_train)\n",
    "        vit_U_test = vit_pca.transform(vit_test)\n",
    "\n",
    "        # ---- Brain PCA (note the .T for samples = images) ----\n",
    "        brain_pca = PCA(n_components=brain_ncomp, random_state=0)\n",
    "\n",
    "        # center each neuron's responses (rows) using training means\n",
    "        train_mean_per_neuron = brain_train.mean(axis=1, keepdims=True)\n",
    "        brain_train_centered = (brain_train - train_mean_per_neuron).T  # (images_train √ó neurons)\n",
    "        brain_test_centered  = (brain_test  - train_mean_per_neuron).T  # (images_test √ó neurons)\n",
    "\n",
    "        # Fit PCA on training images √ó neurons matrix\n",
    "        brain_pca.fit(brain_train_centered)\n",
    "\n",
    "        # Transform test data to get brain PC scores (images_test √ó ncomp)\n",
    "        brain_scores_test = brain_pca.transform(brain_test_centered)\n",
    "\n",
    "        # ---- Compute correlations for significant pairs ----\n",
    "        for (i, j) in cv_results.keys():\n",
    "            try:\n",
    "                r, _ = pearsonr(vit_U_test[:, i-1], brain_scores_test[:, j-1])\n",
    "            except Exception:\n",
    "                r = np.nan\n",
    "            cv_results[(i, j)].append(r)\n",
    "\n",
    "        print(f\"  Fold {fold} done.\")\n",
    "\n",
    "    # ---- Summarize ----\n",
    "    summary = []\n",
    "    for (i, j), rlist in cv_results.items():\n",
    "        rlist = np.array(rlist)\n",
    "        mean_r, std_r = np.nanmean(rlist), np.nanstd(rlist)\n",
    "        summary.append((i, j, mean_r, std_r))\n",
    "\n",
    "    summary = np.array(summary, dtype=[(\"vit_pc\", int),\n",
    "                                       (\"brain_pc\", int),\n",
    "                                       (\"r_mean_cv\", float),\n",
    "                                       (\"r_std_cv\", float)])\n",
    "\n",
    "    np.save(f\"vit_{AREA_NAME}_cv_summary.npy\", summary)\n",
    "\n",
    "    print(\"\\n‚úÖ Cross-validation complete. Results (mean ¬± std):\")\n",
    "    for row in sorted(summary, key=lambda x: -abs(x[\"r_mean_cv\"]))[:10]:\n",
    "        print(f\"  ViT PC{row['vit_pc']:2d} ‚Üî {AREA_NAME} PC{row['brain_pc']:2d} | \"\n",
    "              f\"r_cv = {row['r_mean_cv']:+.3f} ¬± {row['r_std_cv']:.3f}\")\n",
    "\n",
    "    print(f\"\\nüíæ Saved to vit_{AREA_NAME}_cv_summary.npy\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No significant pairs to cross-validate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0dccb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loading ViT embeddings...\n",
      "ViT PCs covering 90% variance: 44\n",
      "üîπ Loading neural responses (VISam)...\n",
      "2040 neurons √ó 118 images\n",
      "VISam PCs covering 90% variance: 61\n",
      "üîπ Computing all pairwise correlations...\n",
      "‚úÖ 1 significant ViT‚ÄìVISam PC pairs (q < 0.05)\n",
      "\n",
      "üîπ Running 5-fold cross-validation on significant pairs...\n",
      "  Fold 1: using 61 brain PCs (78 train imgs)\n",
      "  Fold 2: using 61 brain PCs (79 train imgs)\n",
      "  Fold 3: using 61 brain PCs (79 train imgs)\n",
      "\n",
      "‚úÖ Cross-validation complete. Results (mean ¬± std):\n",
      "  ViT PC 1 ‚Üî VISam PC 1 | r_cv = +0.356 ¬± 0.042\n",
      "\n",
      "üíæ Saved to vit_VISam_cv_summary.npy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "5-fold cross-validation for significant ViT‚ÄìBrain PC correlations.\n",
    "\n",
    "Given the significant pairs from the main correlation script, this tests\n",
    "whether those relationships generalize to unseen images.\n",
    "\n",
    "Author: Maria + Pl2ku üêæ\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import pearsonr\n",
    "from skbio.stats.composition import clr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "VIT_PATH = '/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "NEURAL_PATH = '/home/maria/LuckyMouse/pixel_transformer_neuro/data/processed/hybrid_neural_responses.npy'\n",
    "AREAS_PATH = '/home/maria/MITNeuralComputation/visualization/brain_area.npy'\n",
    "AREA_NAME = 'VISam'                 # choose brain area\n",
    "N_IMAGES, N_TRIALS = 118, 50\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD ViT EMBEDDINGS + PCA\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Loading ViT embeddings...\")\n",
    "with open(VIT_PATH, 'rb') as f:\n",
    "    vit_logits = pickle.load(f)['natural_scenes']\n",
    "\n",
    "embeddings = np.asarray(vit_logits)\n",
    "X = softmax(embeddings, axis=1)\n",
    "X_clr = clr(X + 1e-12)\n",
    "\n",
    "pca_vit_full = PCA(n_components=min(X_clr.shape), random_state=0)\n",
    "pca_vit_full.fit(X_clr)\n",
    "vit_cumvar = np.cumsum(pca_vit_full.explained_variance_ratio_)\n",
    "vit_ncomp = np.searchsorted(vit_cumvar, 0.90) + 1\n",
    "print(f\"ViT PCs covering 90% variance: {vit_ncomp}\")\n",
    "\n",
    "pca_vit = PCA(n_components=vit_ncomp, random_state=0)\n",
    "vit_U = pca_vit.fit_transform(X_clr)  # (images √ó vit_ncomp)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD AND FILTER BRAIN DATA\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"üîπ Loading neural responses ({AREA_NAME})...\")\n",
    "dat = np.load(NEURAL_PATH, mmap_mode='r')\n",
    "areas = np.load(AREAS_PATH, allow_pickle=True)\n",
    "mask = areas == AREA_NAME\n",
    "dat = dat[mask]\n",
    "n_neurons, n_total = dat.shape\n",
    "n_time = n_total // (N_IMAGES * N_TRIALS)\n",
    "dat = dat.reshape(n_neurons, N_IMAGES, N_TRIALS, n_time)\n",
    "X_mean = dat.mean(axis=(2, 3))  # (neurons √ó images)\n",
    "print(f\"{n_neurons} neurons √ó {N_IMAGES} images\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# BRAIN PCA\n",
    "# ---------------------------------------------------------------\n",
    "pca_brain_full = PCA(n_components=min(X_mean.shape), random_state=0)\n",
    "pca_brain_full.fit(X_mean - X_mean.mean(axis=0))\n",
    "brain_cumvar = np.cumsum(pca_brain_full.explained_variance_ratio_)\n",
    "brain_ncomp = np.searchsorted(brain_cumvar, 0.90) + 1\n",
    "print(f\"{AREA_NAME} PCs covering 90% variance: {brain_ncomp}\")\n",
    "\n",
    "pca_brain = PCA(n_components=brain_ncomp, random_state=0)\n",
    "brain_loadings = pca_brain.fit_transform((X_mean - X_mean.mean(axis=0)).T)  # (images √ó brain_ncomp)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# VIŒ§ ‚Üî BRAIN CORRELATION TESTS\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Computing all pairwise correlations...\")\n",
    "r_vals, p_vals, pairs = [], [], []\n",
    "for i in range(vit_ncomp):\n",
    "    for j in range(brain_ncomp):\n",
    "        r, p = pearsonr(vit_U[:, i], brain_loadings[:, j])\n",
    "        r_vals.append(r)\n",
    "        p_vals.append(p)\n",
    "        pairs.append((i + 1, j + 1))\n",
    "\n",
    "r_vals, p_vals = np.array(r_vals), np.array(p_vals)\n",
    "reject, pvals_corrected, _, _ = multipletests(p_vals, alpha=ALPHA_FDR, method='fdr_bh')\n",
    "\n",
    "sig_idx = np.where(reject)[0]\n",
    "if not len(sig_idx):\n",
    "    print(\"‚ùå No correlations survived FDR correction.\")\n",
    "    exit(0)\n",
    "\n",
    "print(f\"‚úÖ {len(sig_idx)} significant ViT‚Äì{AREA_NAME} PC pairs (q < {ALPHA_FDR})\")\n",
    "sig_pairs = [pairs[i] for i in sig_idx]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5-FOLD CROSS-VALIDATION\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\nüîπ Running 5-fold cross-validation on significant pairs...\")\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_results = {tuple(p): [] for p in sig_pairs}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(N_IMAGES)), 1):\n",
    "    # ---- Split images ----\n",
    "    vit_train, vit_test = X_clr[train_idx], X_clr[test_idx]\n",
    "    brain_train, brain_test = X_mean[:, train_idx], X_mean[:, test_idx]\n",
    "\n",
    "    # ---- ViT PCA ----\n",
    "    vit_pca = PCA(n_components=vit_ncomp, random_state=0)\n",
    "    vit_U_train = vit_pca.fit_transform(vit_train)\n",
    "    vit_U_test = vit_pca.transform(vit_test)\n",
    "\n",
    "    # ---- Brain PCA (train images √ó neurons) ----\n",
    "    train_mean_per_neuron = brain_train.mean(axis=1, keepdims=True)\n",
    "    brain_train_centered = (brain_train - train_mean_per_neuron).T\n",
    "    brain_test_centered  = (brain_test  - train_mean_per_neuron).T\n",
    "\n",
    "    n_comps_fold = min(brain_ncomp,\n",
    "                       brain_train_centered.shape[0],\n",
    "                       brain_train_centered.shape[1])\n",
    "    brain_pca = PCA(n_components=n_comps_fold, random_state=0)\n",
    "    brain_pca.fit(brain_train_centered)\n",
    "    brain_scores_test = brain_pca.transform(brain_test_centered)\n",
    "\n",
    "    print(f\"  Fold {fold}: using {n_comps_fold} brain PCs ({len(train_idx)} train imgs)\")\n",
    "\n",
    "    # ---- Correlations for significant pairs ----\n",
    "    for (i, j) in cv_results.keys():\n",
    "        if j > n_comps_fold:\n",
    "            cv_results[(i, j)].append(np.nan)\n",
    "            continue\n",
    "        try:\n",
    "            r, _ = pearsonr(vit_U_test[:, i - 1], brain_scores_test[:, j - 1])\n",
    "        except Exception:\n",
    "            r = np.nan\n",
    "        cv_results[(i, j)].append(r)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# ---------------------------------------------------------------\n",
    "summary = []\n",
    "for (i, j), rlist in cv_results.items():\n",
    "    rlist = np.array(rlist, float)\n",
    "    mean_r, std_r = np.nanmean(rlist), np.nanstd(rlist)\n",
    "    summary.append((i, j, mean_r, std_r))\n",
    "\n",
    "summary = np.array(summary,\n",
    "                   dtype=[(\"vit_pc\", int), (\"brain_pc\", int),\n",
    "                          (\"r_mean_cv\", float), (\"r_std_cv\", float)])\n",
    "np.save(f\"vit_{AREA_NAME}_cv_summary.npy\", summary)\n",
    "\n",
    "print(\"\\n‚úÖ Cross-validation complete. Results (mean ¬± std):\")\n",
    "for row in sorted(summary, key=lambda x: -abs(x[\"r_mean_cv\"]))[:10]:\n",
    "    print(f\"  ViT PC{row['vit_pc']:2d} ‚Üî {AREA_NAME} PC{row['brain_pc']:2d} \"\n",
    "          f\"| r_cv = {row['r_mean_cv']:+.3f} ¬± {row['r_std_cv']:.3f}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved to vit_{AREA_NAME}_cv_summary.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c251fc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brain_pca_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sim = np.abs(np.dot(\u001b[43mbrain_pca_full\u001b[49m.components_, brain_pca_fold.components_.T))\n",
      "\u001b[31mNameError\u001b[39m: name 'brain_pca_full' is not defined"
     ]
    }
   ],
   "source": [
    "sim = np.abs(np.dot(brain_pca_full.components_, brain_pca_fold.components_.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09fe2e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loading ViT embeddings...\n",
      "ViT PCs covering 90% variance: 44\n",
      "üîπ Loading neural responses (VISpm)...\n",
      "VISpm PCs covering 90% variance: 83\n",
      "üîπ Full-data discovery correlations...\n",
      "‚úÖ 2 significant pairs (q<0.05)\n",
      "\n",
      "üîπ Running cross-validation with fixed PCA bases...\n",
      "  Fold 1: 59 test images\n",
      "  Fold 2: 59 test images\n",
      "\n",
      "‚úÖ Cross-validation (fixed basis) complete:\n",
      "  ViT PC 1 ‚Üî VISpm PC 3 | r_cv = +0.432 ¬± 0.066\n",
      "  ViT PC34 ‚Üî VISpm PC57 | r_cv = +0.401 ¬± 0.039\n",
      "\n",
      "üíæ Saved to vit_VISpm_cv_fixedbasis_summary.npy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Fixed-basis cross-validation for ViT‚ÄìBrain PC correlations.\n",
    "\n",
    " - PCA bases are fit once on the full dataset (no re-fitting per fold)\n",
    " - Cross-validation only tests generalization of *the same axes*\n",
    " - Avoids leakage in correlation test, but keeps PC indexing stable\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import pearsonr\n",
    "from skbio.stats.composition import clr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "VIT_PATH   = '/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "NEURAL_PATH = '/home/maria/LuckyMouse/pixel_transformer_neuro/data/processed/hybrid_neural_responses.npy'\n",
    "AREAS_PATH  = '/home/maria/MITNeuralComputation/visualization/brain_area.npy'\n",
    "AREA_NAME   = 'VISpm'\n",
    "N_IMAGES, N_TRIALS = 118, 50\n",
    "ALPHA_FDR = 0.05\n",
    "N_SPLITS  = 2     # 2-fold or whatever you like\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD ViT EMBEDDINGS + PCA (full data)\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Loading ViT embeddings...\")\n",
    "with open(VIT_PATH, 'rb') as f:\n",
    "    vit_logits = pickle.load(f)['natural_scenes']\n",
    "\n",
    "vit_soft = softmax(np.asarray(vit_logits), axis=1)\n",
    "vit_clr  = clr(vit_soft + 1e-12)\n",
    "\n",
    "pca_vit_full = PCA(random_state=0)\n",
    "pca_vit_full.fit(vit_clr)\n",
    "vit_cum = np.cumsum(pca_vit_full.explained_variance_ratio_)\n",
    "vit_ncomp = np.searchsorted(vit_cum, 0.90) + 1\n",
    "print(f\"ViT PCs covering 90% variance: {vit_ncomp}\")\n",
    "W_vit = pca_vit_full.components_[:vit_ncomp]        # frozen ViT basis\n",
    "vit_U_full = vit_clr @ W_vit.T                      # full-data scores\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# LOAD BRAIN DATA + PCA (full data)\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"üîπ Loading neural responses ({AREA_NAME})...\")\n",
    "dat = np.load(NEURAL_PATH, mmap_mode='r')\n",
    "areas = np.load(AREAS_PATH, allow_pickle=True)\n",
    "mask = areas == AREA_NAME\n",
    "dat  = dat[mask]\n",
    "n_neurons, n_total = dat.shape\n",
    "n_time = n_total // (N_IMAGES * N_TRIALS)\n",
    "dat = dat.reshape(n_neurons, N_IMAGES, N_TRIALS, n_time)\n",
    "X_mean = dat.mean(axis=(2,3))                       # neurons √ó images\n",
    "\n",
    "pca_brain_full = PCA(random_state=0)\n",
    "pca_brain_full.fit(X_mean.T)\n",
    "brain_cum = np.cumsum(pca_brain_full.explained_variance_ratio_)\n",
    "brain_ncomp = np.searchsorted(brain_cum, 0.90) + 1\n",
    "print(f\"{AREA_NAME} PCs covering 90% variance: {brain_ncomp}\")\n",
    "W_brain = pca_brain_full.components_[:brain_ncomp]  # frozen brain basis\n",
    "brain_scores_full = X_mean.T @ W_brain.T            # images √ó brain_ncomp\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# INITIAL DISCOVERY (on full data)\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üîπ Full-data discovery correlations...\")\n",
    "r_vals, p_vals, pairs = [], [], []\n",
    "for i in range(vit_ncomp):\n",
    "    for j in range(brain_ncomp):\n",
    "        r, p = pearsonr(vit_U_full[:, i], brain_scores_full[:, j])\n",
    "        r_vals.append(r); p_vals.append(p)\n",
    "        pairs.append((i+1, j+1))\n",
    "r_vals, p_vals = np.array(r_vals), np.array(p_vals)\n",
    "reject, pvals_corr, _, _ = multipletests(p_vals, alpha=ALPHA_FDR, method='fdr_bh')\n",
    "sig_pairs = [pairs[k] for k in np.where(reject)[0]]\n",
    "print(f\"‚úÖ {len(sig_pairs)} significant pairs (q<{ALPHA_FDR})\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CROSS-VALIDATION (fixed bases)\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\nüîπ Running cross-validation with fixed PCA bases...\")\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "cv_results = {tuple(p): [] for p in sig_pairs}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(N_IMAGES)), 1):\n",
    "    vit_test   = vit_clr[test_idx]\n",
    "    brain_test = X_mean[:, test_idx].T  # images √ó neurons\n",
    "\n",
    "    # project test data into the fixed bases\n",
    "    vit_scores_test   = vit_test @ W_vit.T\n",
    "    brain_scores_test = brain_test @ W_brain.T\n",
    "\n",
    "    print(f\"  Fold {fold}: {len(test_idx)} test images\")\n",
    "\n",
    "    for (i,j) in sig_pairs:\n",
    "        r,_ = pearsonr(vit_scores_test[:, i-1], brain_scores_test[:, j-1])\n",
    "        cv_results[(i,j)].append(r)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# ---------------------------------------------------------------\n",
    "summary=[]\n",
    "for (i,j),rlist in cv_results.items():\n",
    "    arr=np.array(rlist,float)\n",
    "    summary.append((i,j,np.nanmean(arr),np.nanstd(arr)))\n",
    "summary=np.array(summary,dtype=[(\"vit_pc\",int),(\"brain_pc\",int),\n",
    "                                (\"r_mean_cv\",float),(\"r_std_cv\",float)])\n",
    "np.save(f\"vit_{AREA_NAME}_cv_fixedbasis_summary.npy\",summary)\n",
    "\n",
    "print(\"\\n‚úÖ Cross-validation (fixed basis) complete:\")\n",
    "for row in sorted(summary,key=lambda x:-abs(x[\"r_mean_cv\"]))[:10]:\n",
    "    print(f\"  ViT PC{row['vit_pc']:2d} ‚Üî {AREA_NAME} PC{row['brain_pc']:2d}\"\n",
    "          f\" | r_cv = {row['r_mean_cv']:+.3f} ¬± {row['r_std_cv']:.3f}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved to vit_{AREA_NAME}_cv_fixedbasis_summary.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
