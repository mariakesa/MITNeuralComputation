{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1ab72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT PCs covering 90% variance: 44\n",
      "\n",
      "=== Area: VISp ===\n",
      "[Area VISp] top-5 mean test canonical corr: [ 0.238  0.131  0.08  -0.027  0.268]\n",
      "[Area VISp] p-values (first 5): [0.1758 0.2707 0.3516 0.5425 0.1089]\n",
      "[Area VISp] FDR<0.05 significant comps: []\n",
      "\n",
      "=== Area: VISl ===\n",
      "[Area VISl] top-5 mean test canonical corr: [0.33  0.131 0.16  0.137 0.05 ]\n",
      "[Area VISl] p-values (first 5): [0.0659 0.3047 0.2468 0.2428 0.4006]\n",
      "[Area VISl] FDR<0.05 significant comps: []\n",
      "\n",
      "=== Area: VISrl ===\n",
      "[Area VISrl] top-5 mean test canonical corr: [ 0.116  0.039  0.058 -0.009  0.016]\n",
      "[Area VISrl] p-values (first 5): [0.2617 0.4416 0.3976 0.5165 0.4785]\n",
      "[Area VISrl] FDR<0.05 significant comps: []\n",
      "\n",
      "=== Area: VISal ===\n",
      "[Area VISal] top-5 mean test canonical corr: [0.267 0.233 0.031 0.011 0.063]\n",
      "[Area VISal] p-values (first 5): [0.1179 0.1269 0.4366 0.5025 0.3826]\n",
      "[Area VISal] FDR<0.05 significant comps: []\n",
      "\n",
      "=== Area: VISam ===\n",
      "[Area VISam] top-5 mean test canonical corr: [0.194 0.213 0.002 0.257 0.039]\n",
      "[Area VISam] p-values (first 5): [0.1748 0.1409 0.4955 0.1159 0.4515]\n",
      "[Area VISam] FDR<0.05 significant comps: []\n",
      "\n",
      "=== Area: VISpm ===\n",
      "[Area VISpm] top-5 mean test canonical corr: [0.131 0.16  0.015 0.101 0.156]\n",
      "[Area VISpm] p-values (first 5): [0.2597 0.2288 0.4535 0.3257 0.2328]\n",
      "[Area VISpm] FDR<0.05 significant comps: []\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Cross-validated CCA (ViT PCs â†” brain PCs) with bootstrap CIs, permutation null, and FDR.\n",
    "\n",
    "Pipeline per area:\n",
    "  1) Repeat-split (even/odd) to remove trial noise.\n",
    "  2) Outer K-fold over stimuli (default 5).\n",
    "  3) Fit brain PCA on TRAIN stimuli (even repeats), project ALL images (even/odd).\n",
    "  4) Fit CCA on TRAIN stimuli: (Zv_train, Zb_train_even).\n",
    "  5) Evaluate canonical correlations on TEST stimuli using ODD repeats:\n",
    "        (Xc_test, Yc_test) = cca.transform(Zv_test, Zb_test_odd)\n",
    "        r_test[i] = corr(Xc_test[:, i], Yc_test[:, i]).\n",
    "  6) Bootstrap CIs over TEST stimuli (no refit).\n",
    "  7) Permutation null: shuffle TRAIN pairing between Zv and Zb, refit CCA, evaluate on the same TEST split.\n",
    "  8) Aggregate across folds: mean spectrum, pool null across folds, p-values, FDR.\n",
    "  9) Save figures and .npz artifacts.\n",
    "\n",
    "Author: Maria + PlÃ¤ku ðŸ¾\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from scipy.special import softmax\n",
    "from skbio.stats.composition import clr\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "VIT_PATH    = '/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "NEURAL_PATH = '/home/maria/LuckyMouse/pixel_transformer_neuro/data/processed/hybrid_neural_responses.npy'\n",
    "AREAS_PATH  = '/home/maria/MITNeuralComputation/visualization/brain_area.npy'\n",
    "\n",
    "AREAS       = [\"VISp\", \"VISl\", \"VISrl\", \"VISal\", \"VISam\", \"VISpm\"]\n",
    "N_IMAGES, N_TRIALS = 118, 50\n",
    "VAR_VIT, VAR_BRAIN = 0.90, 0.90\n",
    "\n",
    "K_OUTER    = 5       # stimulus-level CV folds\n",
    "N_BOOT     = 500     # bootstrap resamples over TEST stimuli\n",
    "N_PERM     = 200     # permutation null (per fold; refits CCA)\n",
    "N_CCA_MAX  = 20      # max canonical comps to report (also bounded by dims)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "OUTDIR     = \"results_cvcca\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def vit_pcs(vit_logits: np.ndarray, var=0.90) -> Tuple[np.ndarray, PCA, int]:\n",
    "    \"\"\"CLR(+eps) â†’ PCA â†’ standardized PCs.\"\"\"\n",
    "    Xv = clr(softmax(np.asarray(vit_logits), axis=1) + 1e-12)\n",
    "    pfull = PCA(random_state=RANDOM_SEED).fit(Xv)\n",
    "    n = int(np.searchsorted(np.cumsum(pfull.explained_variance_ratio_), var) + 1)\n",
    "    p = PCA(n_components=n, random_state=RANDOM_SEED).fit(Xv)\n",
    "    Zv = p.transform(Xv)\n",
    "    # stabilize\n",
    "    Zv = (Zv - Zv.mean(0)) / (Zv.std(0) + 1e-8)\n",
    "    return Zv, p, n\n",
    "\n",
    "def repeat_split_area(dat_area: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"(neurons Ã— images Ã— trials Ã— time) -> (even_mean, odd_mean) as (neurons Ã— images).\"\"\"\n",
    "    idx = np.arange(N_TRIALS)\n",
    "    even, odd = idx[::2], idx[1::2]\n",
    "    X_even = dat_area[:, :, even, :].mean(axis=(2,3))\n",
    "    X_odd  = dat_area[:, :, odd,  :].mean(axis=(2,3))\n",
    "    return X_even, X_odd\n",
    "\n",
    "def brain_pca_on_train(X_even: np.ndarray, img_tr: np.ndarray, X_odd: np.ndarray, var=0.90) -> Tuple[np.ndarray, np.ndarray, PCA, int]:\n",
    "    \"\"\"\n",
    "    Fit PCA on TRAIN images using EVEN repeats; project EVEN/ODD for ALL images into that basis.\n",
    "    Return (Ze_all, Zo_all) of shape (N_IMAGES Ã— ncomp).\n",
    "    \"\"\"\n",
    "    pfull = PCA(random_state=RANDOM_SEED).fit(X_even[:, img_tr].T)\n",
    "    n = int(np.searchsorted(np.cumsum(pfull.explained_variance_ratio_), var) + 1)\n",
    "    p = PCA(n_components=n, random_state=RANDOM_SEED).fit(X_even[:, img_tr].T)\n",
    "\n",
    "    Ze_all = (X_even.T - p.mean_) @ p.components_.T\n",
    "    Zo_all = (X_odd.T  - p.mean_) @ p.components_.T\n",
    "\n",
    "    Ze_all -= Ze_all.mean(0); Zo_all -= Zo_all.mean(0)\n",
    "    return Ze_all, Zo_all, p, n\n",
    "\n",
    "def canonical_corrs(Xc: np.ndarray, Yc: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pearson correlations for paired canonical variables.\"\"\"\n",
    "    Xc = np.asarray(Xc); Yc = np.asarray(Yc)\n",
    "    d = min(Xc.shape[1], Yc.shape[1])\n",
    "    r = np.empty(d)\n",
    "    for i in range(d):\n",
    "        x = Xc[:, i] - Xc[:, i].mean()\n",
    "        y = Yc[:, i] - Yc[:, i].mean()\n",
    "        num = float(np.dot(x, y))\n",
    "        den = float(np.sqrt(np.dot(x, x) * np.dot(y, y)) + 1e-12)\n",
    "        r[i] = num / den\n",
    "    return r\n",
    "\n",
    "def fdr_bh(p: np.ndarray, q=0.05) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Benjaminiâ€“Hochberg FDR (returns boolean mask and cutoff).\"\"\"\n",
    "    p = np.asarray(p)\n",
    "    m = len(p)\n",
    "    order = np.argsort(p)\n",
    "    thresh = q * (np.arange(1, m+1)) / m\n",
    "    passed = p[order] <= thresh\n",
    "    if not np.any(passed):\n",
    "        return np.zeros_like(p, dtype=bool), 0.0\n",
    "    k = np.max(np.where(passed)[0]) + 1\n",
    "    cutoff = p[order[k-1]]\n",
    "    return p <= cutoff, float(cutoff)\n",
    "\n",
    "# -----------------------------\n",
    "# Load data\n",
    "# -----------------------------\n",
    "with open(VIT_PATH, 'rb') as f:\n",
    "    vit_logits = pickle.load(f)['natural_scenes']\n",
    "Zv, vit_pca, vit_n = vit_pcs(vit_logits, VAR_VIT)\n",
    "print(f\"ViT PCs covering {int(VAR_VIT*100)}% variance: {vit_n}\")\n",
    "\n",
    "dat   = np.load(NEURAL_PATH, mmap_mode='r')               # (neurons Ã— (images*trials*time))\n",
    "areas = np.load(AREAS_PATH, allow_pickle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Per-area CV-CCA\n",
    "# -----------------------------\n",
    "for AREA in AREAS:\n",
    "    mask = (areas == AREA)\n",
    "    dA = dat[mask]\n",
    "    if dA.size == 0:\n",
    "        print(f\"[WARN] No data for {AREA}; skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Area: {AREA} ===\")\n",
    "    n_neu, n_total = dA.shape\n",
    "    n_time = n_total // (N_IMAGES * N_TRIALS)\n",
    "    dA = dA.reshape(n_neu, N_IMAGES, N_TRIALS, n_time)\n",
    "\n",
    "    # repeat split\n",
    "    X_even, X_odd = repeat_split_area(dA)\n",
    "\n",
    "    # outer K-fold over stimuli\n",
    "    stim_idx = np.arange(N_IMAGES)\n",
    "    kf = KFold(n_splits=K_OUTER, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # storage across folds\n",
    "    fold_real_corrs: List[np.ndarray] = []\n",
    "    fold_null_means: List[np.ndarray] = []\n",
    "    pooled_null_corrs: List[np.ndarray] = []  # collect all null draws across folds\n",
    "\n",
    "    for fold, (idx_tr, idx_te) in enumerate(kf.split(stim_idx), 1):\n",
    "        img_tr = stim_idx[idx_tr]\n",
    "        img_te = stim_idx[idx_te]\n",
    "\n",
    "        # brain PCA in TRAIN (even repeats)\n",
    "        Ze_all, Zo_all, brain_pca, brain_n = brain_pca_on_train(X_even, img_tr, X_odd, VAR_BRAIN)\n",
    "\n",
    "        # choose CCA dimensionality\n",
    "        ncca = min(N_CCA_MAX, vit_n, brain_n, len(img_tr), len(img_te))\n",
    "        if ncca < 1:\n",
    "            print(f\"[Fold {fold}] ncca<1, skipping fold.\")\n",
    "            continue\n",
    "\n",
    "        # --- Fit CCA on TRAIN stimuli ---\n",
    "        cca = CCA(n_components=ncca, max_iter=1000)\n",
    "        cca.fit(Zv[img_tr], Ze_all[img_tr])\n",
    "\n",
    "        # --- Evaluate on TEST stimuli (use ODD repeats for independent noise) ---\n",
    "        Xc_te, Yc_te = cca.transform(Zv[img_te], Zo_all[img_te])\n",
    "        r_test = canonical_corrs(Xc_te, Yc_te)  # length ncca\n",
    "        fold_real_corrs.append(r_test)\n",
    "\n",
    "        # --- Bootstrap over TEST stimuli (no refit) ---\n",
    "        boot_corrs = np.zeros((N_BOOT, ncca))\n",
    "        for b in range(N_BOOT):\n",
    "            idx = rng.integers(0, len(img_te), len(img_te))\n",
    "            xb = Xc_te[idx]; yb = Yc_te[idx]\n",
    "            boot_corrs[b] = canonical_corrs(xb, yb)\n",
    "\n",
    "        # --- Permutation null: shuffle TRAIN pairing, refit CCA, eval on same TEST ---\n",
    "        null_corrs = np.zeros((N_PERM, ncca))\n",
    "        Zb_train = Ze_all[img_tr]\n",
    "        for b in range(N_PERM):\n",
    "            perm = rng.permutation(len(img_tr))\n",
    "            cca_n = CCA(n_components=ncca, max_iter=1000)\n",
    "            cca_n.fit(Zv[img_tr], Zb_train[perm])     # break stimulus alignment on TRAIN\n",
    "            Xc_n, Yc_n = cca_n.transform(Zv[img_te], Zo_all[img_te])\n",
    "            null_corrs[b] = canonical_corrs(Xc_n, Yc_n)\n",
    "\n",
    "        # summary (per fold)\n",
    "        null_mean = null_corrs.mean(0)\n",
    "        fold_null_means.append(null_mean)\n",
    "        pooled_null_corrs.append(null_corrs)  # pool for area-level p-values\n",
    "\n",
    "        # save fold plot\n",
    "        lo, hi = np.percentile(boot_corrs, [2.5, 97.5], axis=0)\n",
    "        lo_n, hi_n = np.percentile(null_corrs, [2.5, 97.5], axis=0)\n",
    "        x = np.arange(1, ncca+1)\n",
    "\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.plot(x, r_test, 'o-', label='Test canonical corr (real)')\n",
    "        plt.fill_between(x, lo, hi, alpha=0.20, label='Real 95% CI (bootstrap)')\n",
    "        plt.plot(x, null_mean, 'o--', label='Null mean (perm)')\n",
    "        plt.fill_between(x, lo_n, hi_n, alpha=0.20, color='gray', label='Null 95% band')\n",
    "        plt.title(f\"{AREA} â€” CCA fold {fold}  (ncca={ncca}, brainPCs={brain_n})\")\n",
    "        plt.xlabel(\"Canonical component\")\n",
    "        plt.ylabel(\"Correlation on held-out stimuli\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTDIR, f\"{AREA}_fold{fold}_cvcca.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # save fold bundle\n",
    "        np.savez(os.path.join(OUTDIR, f\"{AREA}_fold{fold}_cvcca.npz\"),\n",
    "                 r_test=r_test, boot_corrs=boot_corrs, null_corrs=null_corrs,\n",
    "                 img_tr=img_tr, img_te=img_te, ncca=ncca, brain_n=brain_n)\n",
    "\n",
    "    # ---- Aggregate across folds ----\n",
    "    if len(fold_real_corrs) == 0:\n",
    "        print(f\"[Area {AREA}] no valid folds.\")\n",
    "        continue\n",
    "\n",
    "    # Make same length across folds\n",
    "    L = min(len(r) for r in fold_real_corrs)\n",
    "    real_mat = np.stack([r[:L] for r in fold_real_corrs], axis=0)  # (folds Ã— L)\n",
    "    real_mean = real_mat.mean(0)\n",
    "\n",
    "    # Pool null across folds (concat along samples, then trim to L)\n",
    "    null_all = np.concatenate([n[:, :L] for n in pooled_null_corrs], axis=0)  # (folds*N_PERM Ã— L)\n",
    "    null_mean = null_all.mean(0)\n",
    "\n",
    "    # p-values per component: compare real_mean to distribution of null means.\n",
    "    # Build null distribution of mean-by-fold by resampling null rows to groups of size N_PERM (approx):\n",
    "    # Simpler: treat each null row as an independent draw of the \"mean\" (conservative).\n",
    "    p_vals = np.array([(1 + np.sum(null_all[:, j] >= real_mean[j])) / (1 + null_all.shape[0]) for j in range(L)])\n",
    "\n",
    "    # FDR across components\n",
    "    sig_mask, cutoff = fdr_bh(p_vals, q=0.05)\n",
    "\n",
    "    # Save across-fold plot\n",
    "    x = np.arange(1, L+1)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for r in real_mat:\n",
    "        plt.plot(x, r, color='lightsteelblue', alpha=0.5)\n",
    "    plt.plot(x, real_mean, 'o-', color='tab:blue', label='Real mean (across folds)')\n",
    "    plt.plot(x, null_mean, 'o--', color='tab:gray', label='Null mean (pooled)')\n",
    "    # mark significant\n",
    "    for j in range(L):\n",
    "        if sig_mask[j]:\n",
    "            plt.axvline(j+1, ymin=0, ymax=0.05, color='crimson', lw=2, alpha=0.7)\n",
    "    plt.title(f\"{AREA} â€” CV-CCA across folds (FDR<0.05 comps marked)\")\n",
    "    plt.xlabel(\"Canonical component\")\n",
    "    plt.ylabel(\"Correlation on held-out stimuli\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTDIR, f\"{AREA}_cvcca_acrossfolds.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Print concise summary\n",
    "    top = min(5, L)\n",
    "    print(f\"[Area {AREA}] top-{top} mean test canonical corr: {np.round(real_mean[:top], 3)}\")\n",
    "    print(f\"[Area {AREA}] p-values (first {top}): {np.round(p_vals[:top], 4)}\")\n",
    "    print(f\"[Area {AREA}] FDR<0.05 significant comps: {np.where(sig_mask)[0]+1}\")\n",
    "\n",
    "    # Save summary\n",
    "    np.savez(os.path.join(OUTDIR, f\"{AREA}_cvcca_summary.npz\"),\n",
    "             real_mean=real_mean, null_mean=null_mean,\n",
    "             p_vals=p_vals, sig_mask=sig_mask, fdr_cutoff=cutoff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
